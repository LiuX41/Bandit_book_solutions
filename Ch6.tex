\chapter*{Chapter 6 The Explore-Then-Commit Algorithm}
\label{sec:6}

\noindent\textbf{6.2}
We proceed by comparing the values of $n\Delta$ and $\Delta+\frac{4}{\Delta}\left(1+\max \left\{0, \log \left(\frac{n \Delta^{2}}{4}\right)\right\}\right)$.

\begin{enumerate}
    \item[(a)] If $n\Delta > \Delta+\frac{4}{\Delta}\left(1+\max \left\{0, \log \left(\frac{n \Delta^{2}}{4}\right)\right\}\right)$,
    we have $(n - 1) \Delta^2 > 4 (1 + \max \left\{0, \log \left(\frac{n \Delta^{2}}{4}\right)\right\}) \geq 4$,
    which suggests that $\Delta \geq \frac{2}{\sqrt{n}}$.
    Therefore, \begin{equation*}
        \begin{aligned}
            R_n
            &=\Delta+\frac{4}{\Delta}\left(1+\max \left\{0, \log \left(\frac{n \Delta^{2}}{4}\right)\right\}\right)\\
            &= \Delta+\frac{4}{\Delta}\left(1+\log \left(\frac{n \Delta^{2}}{4}\right)\right)\\
            &= \Delta+\frac{4}{\Delta}+\frac{4}{\Delta}\log(\frac{n\Delta^2}{4})\\
            &\leq \Delta+2\sqrt{n}+\frac{16}{e^4}\sqrt{n}\\
            &=\Delta + C\sqrt{n},
        \end{aligned}
    \end{equation*}
    where the inequality follows from taking $x^* = \frac{2e^4}{\sqrt{n}}$ to maximize $f(x) = \frac{4}{x} log(\frac{nx^2}{4})$.

    \item[(a)] If $n\Delta \leq \Delta+\frac{4}{\Delta}\left(1+\max \left\{0, \log \left(\frac{n \Delta^{2}}{4}\right)\right\}\right)$,
    we consider another two cases:

    \begin{enumerate}
        \item[(i)] If $\Delta \geq \frac{2}{\sqrt{n}}$, by (1) we still have $R_n = n\Delta \leq \Delta+\frac{4}{\Delta}\left(1+\max \left\{0, \log \left(\frac{n \Delta^{2}}{4}\right)\right\}\right) \leq \Delta + C\sqrt{n}$.
        \item[(ii)] If $\Delta < \frac{2}{\sqrt{n}}$, $R_n \leq n\Delta \leq 2\sqrt{n} \leq \Delta + C\sqrt{n}$, where the first inequality is trivial.
    \end{enumerate}
\end{enumerate}

\noindent\textbf{6.3}
Suppose $\Delta_1 = 0$, $\Delta_2 = \Delta > 0$.
Then, the probability that we choose the suboptimal arm (i.e., the second arm) after commitment is
\begin{equation*}
    \begin{aligned}
        \mathbb{P}(T_{2}(n)>m)
        &= \mathbb{P}(\hat{\mu}_{2}(2 m) > \hat{\mu}_{1}(2 m))\\
        &= \mathbb{P}(\left[\hat{\mu}_{2}(2 m) - \mu_2\right] - \left[\hat{\mu}_{1}(2 m) - \mu_1\right]> \Delta\\
        &\leq \exp(-\frac{m\Delta^2}{4}),
    \end{aligned}
\end{equation*}
where the inequality follows from Theorem 5.3.
By letting $\exp(-\frac{m\Delta^2}{4}) = \delta$, we have $m = -\frac{4\log\delta}{\Delta^2}$.
Hence, if we take $m = \min\{\lfloor \frac{n}{2}\rfloor, -\frac{4\log\delta}{\Delta^2}\}$, with high probability we have
\begin{equation*}
    \begin{aligned}
        \bar{R}_{n}
        &= \Delta T_2(n)\\
        &\leq \Delta m\\
        &= \min\{\lfloor \frac{n}{2}\rfloor \Delta, -\frac{4\log\delta}{\Delta}\}
    \end{aligned}
\end{equation*}

\noindent\textbf{6.4} (\textsc{High-probability bounds (ii)}) Repeat the previous exercise, but now
prove a high probability bound on the random regret: $\hat{R}_n=n\mu^{\ast}-\sum^n_{t=1}X_t$.
Compare this to the bound derived for the pseudo-regret in the previous exercise.
What can you conclude?
\begin{proof}
    Denote the reward received in the $t$-th interaction with arm $i$ as $X_{i, t}$.
    From Ex. 6.3, we have that with probability $1 - \delta$,
    \begin{equation*}
        \begin{aligned}
            \hat{R}_{n}
            &\leq \sum_{t = 1}^{n - m} (\mu_1 - X_{1, t}) + \sum_{t = 1}^{m} (\mu_1 - X_{2, t})\\
            &= \sum_{t = 1}^{n - m} (\mu_1 - X_{1, t}) + \sum_{t = 1}^{m} (\mu_2 - X_{2, t}) + m\Delta\,.
        \end{aligned}
    \end{equation*}
    
    Notice that the sum of the first two terms is $(\sqrt{(n - m)^2 + m^2})$-subgaussian.
    Therefore, with probability $(1 - \delta)^2$, we have $\hat{R}_{n} \leq \sqrt{-2[(n - m)^2 + m^2] \log \delta} + m \Delta$.
    This suggests that compared to that derived for the pseudo-regret, the bound on the random regret is less tight with a smaller probability as more randomness is considered.    
\end{proof}

\noindent\textbf{6.5}
Suppose $\Delta_1 = 0$, $\Delta_2 = \Delta > 0$.

\begin{enumerate}
    \item[(a)] By Theorem 6.1, we have
    \begin{equation*}
        \begin{aligned}
            R_n(v)
            &= \Delta \mathcal{E}[T_2(n)]\\
            &\leq m\Delta + (n - 2m)\Delta \exp (-\frac{m\Delta^2}{4})\\
            &\leq m\Delta + n\Delta \exp (-\frac{m\Delta^2}{4})\\
            &\leq m\Delta + n\sqrt{\frac{2}{m}}\exp(-\frac{1}{2})\\
            &=[\Delta + \sqrt{2}\exp(-\frac{1}{2})]n^{\frac{2}{3}},
        \end{aligned}
    \end{equation*}
    where the last inequality follows from taking $x^* = \sqrt{\frac{2}{m}}$ to maximize $f(x) = x\exp(-\frac{m\Delta^2}{4})$,
    and the last equality follows from taking $m = n^{\frac{2}{3}}$.

    Assume there is such a $C > 0$ that leads to $R_{n}(v) \leq \Delta_{v}+C n^{2 / 3}$ for any problem instance $v$ and $n \geq 1$.
    Since trivially $R_n(v) \geq m\Delta$, we have $m\Delta \leq \Delta + Cn^{\frac{2}{3}} \Rightarrow m \leq 1 + \frac{Cn^{\frac{2}{3}}}{\Delta}$.
    Under this circumstance, we can easily find a problem instance $v$ with $\Delta \rightarrow \infty$ such that $m \leq 1$.
    Recalling we only explore $2m$ rounds, we will eventually pull the suboptimal arm with a high probability, which contradicts our assumption.

    \item[(c)] We proceed by comparing the values of $\frac{C \log n}{\Delta}$ and $C \sqrt{n \log (n)}$.
    \begin{enumerate}
        \item[(i)] If $\Delta \geq \sqrt{\frac{\log n}{n}}$, $R_n(v) \leq \Delta + C\frac{\log n}{\Delta} \leq \Delta + C\sqrt{n\log n}$.
        \item[(ii)] If $\Delta < \sqrt{\frac{\log n}{n}}$, $R_n(v) \leq n \Delta \leq \sqrt{n \log n} \leq \Delta + C\sqrt{n\log n}$.
    \end{enumerate}

    \item[(e)] We proceed by comparing the values of $e$ and $n \Delta^2$.
    \begin{enumerate}
        \item[(i)] If $\Delta \geq \sqrt{\frac{e}{n}}$, $R_n(v) \leq \Delta + \frac{C\log(n\Delta^2)}{\Delta} \leq \Delta + \frac{2C}{e}\sqrt{n} = \Delta + C\sqrt{n}$.
        \item[(ii)] If $\Delta < \sqrt{\frac{e}{n}}$, $R_n(v) \leq n \Delta \leq \sqrt{en} \leq \Delta + C\sqrt{n}$.
    \end{enumerate}
\end{enumerate}